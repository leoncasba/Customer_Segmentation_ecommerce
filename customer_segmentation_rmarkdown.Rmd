---
title: "Customer Segmentation on Retail E-commerce Business"
author: "By Leonardo Castro"
output: 
  html_document:
    fig_caption: true
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Introduction**

Customer segmentation is the process of separating customers into groups on the basis of their shared behavior or other attributes. The overall aim of this process is to identify high-value customer base i.e. customers that have the highest growth potential or are the most profitable.

The customer segmentation process allows a company to achieve many things. The most common application is to allow marketers to target marketing campaigns at specific customers to achieve a given marketing goal, such as reactivating lapsed customers or encouraging customers to purchase an additional item.

# **Business Understanding**

## Case Statement

Retail is the process of selling consumer goods or services to customers through multiple channels of distribution to earn a profit. In this context, *Congos* is an e-commerce retail startup based in Costa Rica. They are specialized in selling furniture and home appliances like beds, couches, stoves, fridges, smart TVs, to mention a few. 

Business Development and Marketing Teams are creating new strategies to increase substantially company's income as they are getting more investment in order to keep growing and make bigger its product catalog. 

There is data from over 23 000 *Congos'* transactions made during 2018 and 2019, its first two years of acting in the e-commerce market. This valuable asset (**raw data**) can be converted into a powerful knowledge resource by converting it into a customer segmentation analysis which allows company to whom direct his promotions, sales and marketing efforts. 

## Objective

The **objective** of this analysis is to model and differentiate the characteristics and typologies of the Congos' customers in order to  increase marketing efficiency by directing efforts specifically toward the designated segment in a manner consistent and smart.


## Business Benefit

To help Business Development and Marketing Teams to develop tailor-made marketing campaigns and differentiation strategies based on the characteristics of each customer.
  
## Scope

This analysis parts from the hypothesis that all the customers being analyzed are trusted customers, for hence, eligible customers to get a loan. I am not analyzing whether the customers are good or bad payers.

Also I want to clarify all the insights come strictly from the data and not from subjective opinion. However, we should have opinion from a Subject Matter Expert (SME) to get better understanding of some policies or rules on loan and fin-tech business.

## Key Business Questions

  * How much do customers spend every month?
  * What is the expected accuracy or confidence of the model developed?
  * What is the most important variable/s which defines if a customer will get a loan customer?

## Expected Outcomes

To understand the customer segmentation analysis by characterizing each segment and providing recommendations based on segment profile.
  
# **Methodology & Analytics Techniques Used**

  * Data understanding
  * Data cleaning and preparation.
  * Exploratory data analysis.
  * RFM Analysis.
  * K-means Clustering
    
```{r load packages, warning=FALSE, message=FALSE}
#These are the R packages used for the analysis.
library(readxl)
library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(lubridate)
```
    
    
## Data Understanding

  * Data consists in Congos' transactions made by customers during the period of 2018-04-01 and 2019-09-28.
  * Data is anonymized and it was provided during a Data Analytics course. You can downloaded here directly from my GitHub repo [**here.**](https://github.com/leoncasba/Customer_Segmentation_ecommerce/blob/main/Customer_Segmentation.xlsx)
  * The data set has 12 columns and 23208 rows.
  * Data dictionary:
    * **Transaction:** transaction unique number identifier.
    * **Year:** year transactions has been made.
    * **Month:** month transactions has been made.
    * **Day:** day transactions has been made.
    * **Customer_Code:** customer's unique identification code.
    * **Age:** customer's age.
    * **Product_Code:** product unique identifier code.
    * **Product_Name:** product name.
    * **Product_Price:** product price per unit ($).
    * **Quantity:** number of product units bought in each transaction. 
    
 
    ```{r}
#Read database
data <- read_excel("Customer_Segmentation.xlsx")

#Head 5 first rows from database
kable(head(data,5),  caption="**Table 1.** First five rows from bank database.")

```    

## Data Cleaning and Preparation.

Findings and actions:

  * There are not missing values on the database.
  * Variables are being correctly recognized as numeric and character depending on its nature.
  * Having a complete transaction date would be easier and better to manipulate for the analysis, so I proceed creating this variable.
  * Categorical variables have been read as numerical, so I proceed converting them to factor, as we need it for the further steps.
  * Some variables are no longer suitable for the analysis: *Year*, *Month* and *Day* (Transaction_Date has been created). I proceed eliminating those variables.
  
```{r}
#Function to get percentage of missing values
NAporcent <- function(x, ndec=2){
  porcent=(sum(is.na(x))/length(x))*100
  p2 = round(porcent, digits=ndec)
}

#Look if there are missing values
sum(apply(data, 2, NAporcent))

#Check variables' nature
summary(data)
```


```{r}
#Create TransactionDate
data$TransactionDate = ymd(paste0(data$Year,"-",data$Month,"-",data$Day))
class(data$TransactionDate) #check is date type

#Eliminate variables no longer necessary in the analysis
data_prepared <- data[ , -c(2, 3, 4)]  
```
  
## Exploratory Data Analysis

  * **How much has been sold every month by year??**
  
As we can see on **Figure 1**, revenue differs by year but basically follows a similar pattern. Sales peak occurred during July for both years, being 2018 more successful, overpassing the 800k dollars, probably product of some kind of promotion occurred during this month. Also is interestingto notice there is a gap between years on May of around 50k dollars, being more successful May 2019. Business team can replicate the success of sales strategies in this month to be implemented in further campaigns.
  
```{r, fig.align='center', fig.height=7, fig.width=14,fig.cap = '**Figure 1.** Total Revenue per Month ($).', message=FALSE, warning=FALSE}
q1 <- data_prepared %>% group_by(year(TransactionDate), month(TransactionDate)) %>% summarize(total=sum(Product_Price*Quantity)) %>% rename(Year='year(TransactionDate)', Month='month(TransactionDate)', Total=total)

ggplot(q1, aes(x=factor(Month), y=(Total/1000), group=factor(Year), colour=factor(Year)))+geom_line(size=1.5)+ geom_point(size=3) +
  labs(y="Total revenue ($ thousands)", x="Month", colour="Year") +theme_classic(base_size = 18)
```

  * **Which are the top 10 products by total revenue?**
  
**Figure 2** shows top 10 products by total revenue. Highlighted in red is the top product: Laptops. It has reached a total revenue over 3 Million dollars. This simple visualization have shown which are the more profitable products in the company so far, which represents a good focus to start redirecting product marketing campaigns to its customers after knowing the segmentation.
  
```{r, fig.align='center', fig.height=7, fig.width=14,fig.cap = '**Figure 2.** Total Revenue per Month ($).', message=FALSE, warning=FALSE}
q3 <- data_prepared %>% group_by(Product_Name) %>% summarise(Total_Revenue_by_Product=sum(Product_Price*Quantity)/1000) %>% arrange(desc(Total_Revenue_by_Product)) %>% top_n(10)

ggplot(q3, aes(x=reorder(factor(Product_Name),Total_Revenue_by_Product), y=Total_Revenue_by_Product, fill = ifelse(Product_Name == "Laptop", "Highlighted", "Normal") ))+geom_col()+theme_classic(base_size = 18)+coord_flip()+theme(legend.position = "none", axis.title.y = element_blank())+labs(y="Total revenue by product ($ thousands)")
```
  * How are distributed the customers around the country and what is the age group?
  
```{r}

```
  

## Recency Frequency Monetary Analysis

Recency Frequency Monetary (RFM) analysis allows to segment customers by the frequency and value of purchases and identify those customers who spend the most money.

  * **Recency** means how long it’s been since a customer bought any product (**days**).
  * **Frequency** represents how often a customer buys  (**number of purchases**).
  * **Monetary value** is the total value of purchases a customer has made (**total amount in $**).
  
```{r}
NOW=max(data_prepared$TransactionDate)
#The last transaction date is 2019-12-28, 8so I will use this date to calculate Recency.

#Recency-Frequency-Monetary
RFM <- data_prepared %>% group_by(Customer_Code) %>% summarise(Recency=as.numeric(NOW-max(TransactionDate)), Frequency=n(), Monetary=sum(Quantity*Product_Price))
head(RFM, 5)
```

Once is done the RFM table, I split the metrics into segments using quantiles. 

```{r}
quantile_table <- (apply(RFM[,-1] , 2, quantile))
kable(quantile_table,caption="**Table 2.** RFM table - Quantiles.")
```

I assigned a quantile "score" from 1 to 4 to each *Recency*, *Frequency* and *Monetary* respectively, regarding its position:

  * 4 is the highest value (customers is on the top of the evaluated value), and 1 is the lowest value (customer is on the bottom of the evaluated value).
  * A final RFM score (Overall Value) is calculated simply by concatenating individual RFM score numbers:
  
$$RFM \ Score = R_{quartile} + F_{quartile} + M_{quartile}$$

```{r}
quantiles <- apply(RFM[,-1] , 2, ntile, n=4)
colnames(quantiles) <- c("R_quartile",	"F_quartile",	"M_quartile")
RFM_q <- cbind(RFM, quantiles)
RFM_q$RFM_score <- paste0(as.character(RFM_q$R_quartile),as.character(RFM_q$F_quartile),as.character(RFM_q$M_quartile))
kable(head(RFM_q,5),  caption="**Table 3.** RFM scores table - Sample of five customers.")
```
The table below (adapted from [**here.**](https://runawayhorse001.github.io/LearningApacheSpark/rfm.html)) show which means each segment and its respective marketing strategy according with its RFM score:

<center>
![](C:/Users/Leo/Desktop/Portfiolo/Customer_Segmentation_ecommerce/RFM_table.JPG)
</center>


Now it is possible to categorize each customer by its respective segment. **Figure 3** shows number of customers by segment, where..



```{r, fig.align='center', fig.height=7, fig.width=14,fig.cap = '**Figure 3.** Number of customers by RFM segment (Excluding Category "Others").', message=FALSE, warning=FALSE}
#Set each level to customers

RFM_q$Category <-
  ifelse(RFM_q$RFM_score == '144', "Best Customers",
    ifelse(RFM_q$F_quartile == '4', "Loyal Customers",
      ifelse(RFM_q$M_quartile == '4', "Big Spenders", 
        ifelse(RFM_q$RFM_score == '333' | RFM_q$RFM_score == '444' | RFM_q$RFM_score == '433' , "Almost Lost", 
          ifelse(RFM_q$RFM_score == '411', "Lost Cheap Customers", "Others")))))

group <- RFM_q %>% group_by(Category) %>% summarize(N_Customers=n()) 
group$Category <- factor(group$Category,                                   
                  levels = group$Category[order(group$N_Customers, decreasing = TRUE)])

ggplot(group[-6,], aes(x=Category, y=N_Customers))+geom_col(fill = "#0073C2FF")+theme_classic(base_size = 18)+labs(y="Number of Customers", x="Segment")+geom_text(aes(label = N_Customers), vjust = 2, cex=6, color = "white")

```

## K-means Clustering

K-Means clustering is an unsupervised machine learning algorithm used to find homogeneous subgroups within a population. To process the learning data, the K-means algorithm starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, and then performs iterative (repetitive) calculations to optimize the positions of the centroids. It halts creating and optimizing clusters when either:

  * The centroids have stabilized — there is no change in their values because the clustering has been successful.
  * The defined number of iterations has been achieved.

Before proceed with the K-Means algorithm, data preparation is required in order to obtain a good performance on the modeling, for hence, the input data requires:

  * **1. No outliers.**
  
As we can see Frequency and Monetary variables have values over the interquartile range, however, nothing to be worried about, it seems like there is someone who represents a huge amount of monetary amount as well as several customers which buy really frequently. In the other side, recency shows multiple values out of the interquartile range, it seems like data distribution is skewed more than the existance of outliers, for hence, I will continue with the assumptions.
  
```{r, fig.align='center', fig.height=5, fig.width=9,fig.cap = '**Figure 4.** Box Plot - Looking for outliers").', message=FALSE, warning=FALSE}
#Checking outliers
pivot <- RFM %>% pivot_longer(Recency:Monetary)
ggplot(data = pivot, aes(x=name, y=value)) + 
             geom_boxplot(fill = "#0073C2FF")+facet_wrap( ~ name, scales="free")+theme_classic(base_size = 18)+labs(y="Value", x="Variables (R-F-M)")


```

  * Data has symmetric distribution of variables (it isn’t skewed).
  
As we can see on the figures below Frequency and Monetary Value have normal distribution, however recency is right-skewed as I assumed on the previous analysis. This means, data will need a transformation in order to use on further K-means algorithm.


```{r, , fig.align='center', fig.height=5, fig.width=9,fig.cap = '**Figure 5.** Checking variables distribution").', message=FALSE, warning=FALSE}
#Check distribution of each variable
ggplot(RFM, aes(Recency))+geom_histogram(aes(y = ..density..), colour = 1, fill = "white")+geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25)+theme_classic(base_size = 18)+ggtitle("Recency distribution")

ggplot(RFM, aes(Frequency))+geom_histogram(aes(y = ..density..), colour = 1, fill = "white")+geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25)+theme_classic(base_size = 18)+ggtitle("Frequency distribution")

ggplot(RFM, aes(Monetary))+geom_histogram(aes(y = ..density..), colour = 1, fill = "white")+geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25)+theme_classic(base_size = 18)+ggtitle("Monetary Value distribution")
```
 
```{r, fig.align='center', fig.height=5, fig.width=9,fig.cap = '**Figure 6.** Checking log transformed Recency data").', message=FALSE, warning=FALSE}
#Checking distribution on log transformed recency data.  I added a small constant as log transformation demands all the values to be positive.
ggplot(RFM, aes(log10(Recency+1)))+geom_histogram(aes(y = ..density..), colour = 1, fill = "white")+geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25)+theme_classic(base_size = 18)

#Creating matrix for next step: scaling
RFM_2 <- cbind(RFM[, c(3,4)], (log10(RFM$Recency+1)))
```

  * Variables are on the same scale.
  
Since K-means algorithm works with euclidean distances we need to scalate the data. It means transforming data in order the mean is equal 1 and the standard deviation equal 1.

```{r}
#Scale values
scaled_values <- apply(RFM_2, 2, scale, center = TRUE, scale = TRUE)

#Check if are correctly scaled.
apply(scaled_values, 2, mean)
apply(scaled_values, 2, sd)
```

```{r}
test = kmeans(scaled_values, centers=5, nstart=20)
summary(test)
#print(test$cluster)

plot(scaled_values, col = test$cluster,
     main = "k-means with 5 clusters", 
     xlab = "", ylab = "")
```

